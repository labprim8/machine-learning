---
title: "Practical Machine Learning"
author: "G Nugent"
date: "23 January 2015"
output: html_document
---

## Introduction

The purpose of this project is to build a model using data generated from correct and incorrect weightlifting exercise methods to predict which of these methods is being carried out. The data was generated by asking 6 participants were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different fashions. One group was done in the correct fashion and the other 4 were common mistakes that can be replicated.

Read more: http://groupware.les.inf.puc-rio.br/har#ixzz3PeHcLLMP

Using this data it should be possible to build a model so that the method in which the exercise can be classified into one of the 5 classes.


## Preliminary Data Analysis

The weightlifting exercise data downloaded using the following method. This data was split into two sets prior to download. The first set contains the training data on which to build the model and the second set is a testing set for the purpose of grading the model for the coursera model.

```{r, echo=TRUE, cache=TRUE}
#download training data
download.file('https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv', 'pml-training.csv', method="curl")
#download test data
download.file('https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv', 'pml-testing.csv',method="curl")
```

All the modeling and analysis has been run using the training set data.

```{r,echo=TRUE, cache=TRUE}
full_data <- read.csv('pml-training.csv')
dim(full_data)
```

This data set contains 160 variables and 19622 records, a summary of this data will help identify the variables that can be used to build the model (see appendix 1). 

From the summary, there are a set of variables that have numerical data for all 19622 records and also have a meaning in terms of the data that have been collected and for any data that would be collected in the future. 

Details of the experiment design there was sensors placed on the belt, dumbbell, forearm and arm. For each of these sensors the following measurements is kept along with classe which contains the exercise type:

* yaw
* roll
* pitch
* total acceleration
* magnet x
* magnet y
* magnet z
* acceleration x
* acceleration y
* acceleration z
* gyro x
* gyro y
* gyro z
  
Using the grep function these variables (plus the 'classe' variable) are kept to leave 53 variables. 

```{r, echo=TRUE}
clean_data <- clean_data <- full_data[,grep("^(classe|gyros|accel|magnet|roll|pitch|yaw|total_accel)", names(full_data))]
```

These 53 variables were analysed to see if any of the variables have zero or near zero variance and as such would not add to the model (See appendix 2). None of these variables have to be removed under these conditions.

### Cross validation
To validate the model prior to using it to predict the outcomes a validation set is created. This will enable out of sample errors to be calculated for the model. 75% of the testing data is used to build the model and the the remaining 25% is held back.

```{r, echo=TRUE}
library(caret)
```
```{r, echo=TRUE, cache=TRUE}
set.seed(1979)

inTraining <- createDataPartition(y=clean_data$classe, p=0.75, list=F)
training <- clean_data[inTraining,]
validation <- clean_data[-inTraining,] 
```

The following plot is a matrix plot of the pitch, yaw, roll and total acceleration of the forearm sensor. There seems to be some separation in the the groups when looking at the roll, pitch and yaw, although it doesn't look to be a linear relationship.

```{r, echo=TRUE, cache=TRUE}
featurePlot(training[,grep("forearm$",names(training))],training[,53],"pairs",auto.key = list(columns = 5))
```

Plotting (see below) the acceleration of the sensors and the magnets in the xyz planes for all of the sensors shows that is no obvious differences between the classes using these variables

```{r, echo=TRUE}
featurePlot(training[,grep("^magnet",names(training))],training[,53],"box")
featurePlot(training[,grep("^accel",names(training))],training[,53],"box")
```

## Data Modelling

For classification problems there are a number of different methods that can used to model the data. For this data set linear discrimination analysis (LDA) is not applicable due to the data in the variables chosen so far not being completely separated in a linear fashion. In some of the plots the data could be classified using the Quadratic discriminant analysis (QDA) method.

This first model is trained as follows, using a 10 fold internal cross validation.

```{r, echo=TRUE, cache=TRUE}
mod.qda <- train(classe ~ ., data=training, trControl = trainControl(method="cv", number=10), method="qda")
mod.qda
```

From the internal cross validation, this model has an accuracy of 89.6%. For the held out validation set the accuracy is 89.9%.

```{r,echo=TRUE, cache=TRUE}
pred.qda <- predict(mod.qda, validation[,-53])
confusionMatrix(pred.qda, validation$classe)
```

Another method that can used in classification modelling is a nearest neighbor approach. This method works better when the variables is scaled and centered because of the variation in scales can effect the outcome.

```{r,echo=TRUE, cache=TRUE}
preproc <- preProcess(training[,-53], method=c("scale","center"))
proc_train <- predict(preproc, training[,-53])
proc_valid <- predict(preproc, validation[,-53])
```

Now to build a nearest neighbor model, again this model was built with a 10 fold cross validation in the predict method.
```{r,echo=TRUE, cache=TRUE}
mod.knn <- train(training$classe ~ ., data=proc_train, trControl = trainControl(method="cv", number=10), method="knn")
mod.knn
```

The using the default tuning parameters it seems that k=5 gives the best results internally. this has a accuracy of  96.5%. For the held out validation set this accuracy is 97.1%

```{r,echo=TRUE, cache=TRUE}
pred.knn <- predict(mod.knn, proc_valid)
confusionMatrix(pred.knn, validation$classe)
```

Another way that classification can be predicted is using a tree classification method. 

```{r, echo=TRUE, cache=TRUE}
mod.tree <- train(classe ~ ., data=training, trControl = trainControl(method="cv", number=10), method="rpart")
mod.tree
```

this best method from this only gives an accuracy of 50.1% from the internal cross-validation. The external validation gives an accuracy of 49.8%

```{r, echo=TRUE,, cache=TRUE}
pred.tree <- predict(mod.tree, validation)
confusionMatrix(pred.tree, validation$classe)
```

To improve on this poor result, the random forest method can be used, this creates a number of tree models using a random selection of the variables.

```{r, echo=TRUE, cache=TRUE}
mod.rf <- train(classe ~ ., data=training, trControl = trainControl(method="cv", number=10), method="rf")
mod.rf
```

In the final model the accuracy is 99.3% from the internal cross validation. When the external validation set is predicted and compared the accuracy is 99.4%

```{r, echo=TRUE,, cache=TRUE}
pred.rf <- predict(mod.rf, validation)
confusionMatrix(pred.rf, validation$classe)
```

## Test Data

The data for the marked test set is loaded in and the results predicted using the random forest method.

```{r,echo=TRUE}
test <- read.csv('pml-testing.csv')
pred.test <- predict(mod.rf, test)
```

To prepare the files for submission the predicted classes need to be converted from a factor to a character, and using a function for write these out to separate files, the answers were written to file and submitted,

```{r,echo=TRUE,cache=TRUE}
answers <- as.character(pred.test)

pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

pml_write_files(answers)
```

## Conclusions

In conclusion the class of exercise was predicted using different models and their errors where compared using both an internal cross validation and validation set excluded from training set. from the four models evaluated the random forest method performed the best with an accuracy of >99%. The neighest neighbor model where k = 5 also performed well with an accuracy of >96%. 

## Appendix 1
summary of full data

```{r, echo=TRUE}
summary(full_data)
```
## Appendix 2
Results of near zero variance analysis

```{r, echo=TRUE}
nearZeroVar(clean_data, saveMetrics = TRUE)
```